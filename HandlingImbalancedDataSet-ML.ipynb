{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d1868d6",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17e0bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9734dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bad1a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum() # no null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89cd96ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()  # fraud detection based on class so we take value counts\n",
    "\n",
    "# as there is huge difference it is imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e132912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segregating X and Y to Independent and dependent features\n",
    "\n",
    "X=df.drop('Class',axis=1)\n",
    "y=df.Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc22f039",
   "metadata": {},
   "source": [
    "### CrossValidation like KFold and HyperparameterTuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50c57bf",
   "metadata": {},
   "source": [
    "Imbalanced dataset does not heavely impact ensembled techniques or decission trees are actually used.\n",
    "\n",
    "During imbalanced dataset donot check just the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ee125a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np #to apply kfold\n",
    "from sklearn.model_selection import GridSearchCV #CrossValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8c26273",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_class=LogisticRegression()\n",
    "# crossvalidation\n",
    "grid={'C':10.0**np.arange(-2,3),'penalty':['l1','l2']}# 'C' is hyperparameter\n",
    "# grid is giving some list of values for performing hyperparameter tuning\n",
    "# penalty key is just like regularization \n",
    "\n",
    "cv=KFold(n_splits=5,random_state=None,shuffle=False)  # applying crossvalidation for kfold splits as 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37117b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We perform train test split before Grid SearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61993bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "25 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.83218768        nan 0.85026531        nan 0.84852864\n",
      "        nan 0.84274544        nan 0.84072114]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=GridSearchCV(log_class,grid,cv=cv,n_jobs=-1,scoring='f1_macro')# f1_macro is scoring parameter we can also use accuracy \n",
    "clf.fit(X_train,y_train)             #n_jobs uses all the cores of the computer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64f7e058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85249    47]\n",
      " [   43   104]]\n",
      "0.9989466661985184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.69      0.71      0.70       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.84      0.85      0.85     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=clf.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "# if for imbalanced dataset if we get better accuracy someting is wrong\n",
    "\n",
    "# we think to increase the precission and recall values \n",
    "#and to reduce the false +ve and -ve values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bc5bcab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we do this Random Forest in the last\n",
    "# RanfomForest is better than all the techiques better than under/OverSampling smote etc...\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier() # decisssion tree plays an importantent role it makes a hierarchicle structure\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "# to increase or decrease False+ve and _ve values we can make use of class_weight sattribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e02ca04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85286    10]\n",
      " [   31   116]]\n",
      "0.9995201479348805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.92      0.79      0.85       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.96      0.89      0.92     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89711f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199019\n",
       "1       345\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# increaseing th class weights\n",
    "y_train.value_counts()\n",
    " # here for each 1's in the class we increase weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44f69039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to increase the class weights we need dictionaries\n",
    "class_weight=dict({0:1,1:100})\n",
    "\n",
    "# this implies for 0's increase by 0 times, for 1's increase by 100 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0885bdd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 1, 1: 100})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier(class_weight=class_weight) # decisssion tree plays an importantent role it makes a hierarchicle structure\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28def39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85289     7]\n",
      " [   34   113]]\n",
      "0.9995201479348805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.94      0.77      0.85       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.97      0.88      0.92     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4677c5d",
   "metadata": {},
   "source": [
    "### Undersampling \n",
    "\n",
    "we try to reduce the points of maximum labels/class values\n",
    "\n",
    "By doing this we loose some data (apply only for lessdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69484fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199019\n",
       "1       345\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()\n",
    "\n",
    "# we reduce 80% of the 0's class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8760961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter# counts the no of 0's and 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65a3250f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of classer before fitCounter({0: 199019, 1: 345})\n",
      "No of classer before fitCounter({0: 345, 1: 345})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "ns=NearMiss()\n",
    "X_train_ns,y_train_ns=ns.fit_resample(X_train,y_train)\n",
    "print(\"No of classer before fit{}\".format(Counter(y_train)))\n",
    "print(\"No of classer before fit{}\".format(Counter(y_train_ns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44bb0bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier()\n",
    "classifier.fit(X_train_ns,y_train_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c63e7f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74348 10948]\n",
      " [    6   141]]\n",
      "0.8717975726507731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93     85296\n",
      "           1       0.01      0.96      0.03       147\n",
      "\n",
      "    accuracy                           0.87     85443\n",
      "   macro avg       0.51      0.92      0.48     85443\n",
      "weighted avg       1.00      0.87      0.93     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "# presision is gone many errors in test dataset[74348 10948]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7061a797",
   "metadata": {},
   "source": [
    "### OverSampling\n",
    "\n",
    "We imput and increase the values having the lowernumber of values\n",
    "\n",
    "It is inverse of UnderSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b824e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "def521e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of classer before fitCounter({0: 199019, 1: 345})\n",
      "No of classer before fitCounter({1: 199019, 0: 199019})\n"
     ]
    }
   ],
   "source": [
    "os=RandomOverSampler()\n",
    "X_train_os,y_train_os=os.fit_resample(X_train,y_train)\n",
    "print(\"No of classer before fit{}\".format(Counter(y_train)))\n",
    "print(\"No of classer before fit{}\".format(Counter(y_train_os)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7bd7ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier()\n",
    "classifier.fit(X_train_os,y_train_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "50a8c9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85290     6]\n",
      " [   30   117]]\n",
      "0.9995786664794073\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.95      0.80      0.87       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.98      0.90      0.93     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "#false -ve is redused"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca644b2d",
   "metadata": {},
   "source": [
    "#### SMOTE Tomek\n",
    "\n",
    "It creates more/new points of the lowest numbers\n",
    "\n",
    "It takes more time w.r.t oversampling\n",
    "\n",
    "It is the combinatio of both undersampling and oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ddc25584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1725fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "smo=SMOTETomek()\n",
    "X_train_smo,y_train_smo=smo.fit_resample(X_train,y_train)\n",
    "print(\"No of classer before fit{}\".format(Counter(y_train)))\n",
    "print(\"No of classer before fit{}\".format(Counter(y_train_smo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64821516",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier=RandomForestClassifier()\n",
    "classifier.fit(X_train_smo,y_train_smo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a661887",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc3b796",
   "metadata": {},
   "source": [
    "### Ensemble Techniques\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8b937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import EasyEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c81d6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "easy=EasyEnsembleClassifier()\n",
    "easy.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c1b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=easy.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ae6941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2d93f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8129c181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0302fe0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5720546f",
   "metadata": {},
   "source": [
    "if dataset small ill go with undersample focus on performance matrix like : accurace,precession,recall F1-score\n",
    "\n",
    "Apart from that based on domain knowledge weathere we should reduce false +ve _ve based on that I'll be considering my ROC score(i.e Probability value) \n",
    "\n",
    "Finally smote, oversampling by involving around the understanding performance matrix\n",
    "\n",
    "Finally if above is Not Working, I'll go with ensemblled techniques like decission trees, random forestxgboost where i can provid class width parameters\n",
    "\n",
    "Ensembled techniques prevents imbalence datasset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8629d54",
   "metadata": {},
   "source": [
    "We apply sampling techniques during model creation coz we need to validate/verify it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a339f975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875ab02d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
